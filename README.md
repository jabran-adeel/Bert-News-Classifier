# ğŸ“° BERT News Classifier

## ğŸš€ Overview

**BERT News Classifier** is a fine-tuned transformer-based NLP model built using Hugging Faceâ€™s `transformers` library. It classifies news headlines/articles into four major categories:

- ğŸŒ World  
- ğŸˆ Sports  
- ğŸ’¼ Business  
- ğŸ§ª Science/Technology  

This project uses the **AG News dataset** and fine-tunes the `bert-base-uncased` model for accurate multi-class text classification.

---

## ğŸ“¦ Features

- âœ… Text preprocessing & tokenization using `AutoTokenizer`
- âœ… Fine-tuning BERT on AG News with Hugging Face `Trainer`
- âœ… Model evaluation with **accuracy** & **confusion matrix**
- âœ… Visualization of results for better interpretability
- âœ… Save & reuse trained model checkpoints

---

## ğŸ› ï¸ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/jabran-adeel/bert-news-classifier.git
   cd bert-news-classifier
   
## Install required packages:
```bash
pip install -r requirements.txt
```
## â–¶ï¸ Usage:
Run the main training & evaluation script:
```bash
python main.py
```
After training, the model will automatically evaluate and generate a confusion matrix as `confusion_matrix.png`.

## ğŸ“Š Evaluation
<p align="center"> <img src="confusion_matrix.png" alt="Confusion Matrix" width="600"/> </p>
Metric: Accuracy

Model: `bert-base-uncased`

Epochs: 3

Batch Size: 8

Max Length: 512

## ğŸ“š Technologies Used
ğŸ¤— Transformers

ğŸ”¥ PyTorch

ğŸ§  Scikit-learn

ğŸ“Š Matplotlib & Seaborn

ğŸ“‘ Datasets (AG News)

## ğŸ™Œ Author
Made with â¤ï¸ by [Jabran Adeel](https://github.com/jabran-adeel)

Connect with me on [LinkedIn](https://www.linkedin.com/in/jabran-adeel/)

## ğŸ“ License
This project is open source under the MIT License.
